ã€Œãƒãƒ¼ãƒˆã‚’æ”¹é€ ã—ã¦OOFã‚’å–ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ãŸã‚ã® **æœ€ä½é™ã®ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³é›†** ã‚’æ•´ç†ã—ã¾ã™ã€‚
åŸºæœ¬çš„ã«ã¯ã€Œã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã©ã“ã« `oof_preds[val_idx] = ...` ã‚’å…¥ã‚Œã‚‹ã‹ï¼Ÿã€ãŒéµã§ã™ã€‚

---

# ğŸ”‘ OOFæ”¹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³é›†

## â‘  KFold / StratifiedKFold ã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆ

ã‚ˆãã‚ã‚‹å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

```python
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import numpy as np

kf = KFold(n_splits=5, shuffle=True, random_state=42)
oof_preds = np.zeros(len(train_x))

for fold, (train_idx, val_idx) in enumerate(kf.split(train_x, train_y)):
    model = lgb.LGBMRegressor()
    model.fit(train_x.iloc[train_idx], train_y.iloc[train_idx])
    val_pred = model.predict(train_x.iloc[val_idx])
    
    oof_preds[val_idx] = val_pred
    print(f"Fold {fold+1} RMSE:", mean_squared_error(train_y.iloc[val_idx], val_pred, squared=False))

np.save("oof.npy", oof_preds)
```

### ãƒã‚¤ãƒ³ãƒˆ

* `val_idx` ã« fold ã”ã¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå…¥ã£ã¦ã„ã‚‹
* `oof_preds[val_idx] = val_pred` ãŒ **å¿…é ˆè¡Œ**

---

## â‘¡ cross\_val\_score / cross\_val\_predict ã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆ

Scikit-learnæµã«ç°¡ç•¥åŒ–ã—ã¦æ›¸ã„ã¦ã„ã‚‹ãƒãƒ¼ãƒˆã«é­é‡ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

```python
from sklearn.model_selection import cross_val_predict
from sklearn.linear_model import Ridge

model = Ridge()
oof_preds = cross_val_predict(model, train_x, train_y, cv=5)
np.save("oof.npy", oof_preds)
```

### ãƒã‚¤ãƒ³ãƒˆ

* `cross_val_predict` ã‚’ä½¿ãˆã° **ä¸€ç™ºã§OOFãŒå–ã‚Œã‚‹**
* ãŸã ã— LightGBM ã‚„ XGBoost ã§ã¯ä½¿ãˆãªã„ã“ã¨ãŒå¤šã„ï¼ˆscikit-learn APIã§åŒ…ã‚“ã§ã„ãªã„ã¨ç„¡ç†ï¼‰

---

## â‘¢ train\_test\_split ã‚’æ‰‹ä½œæ¥­ã§ãƒ«ãƒ¼ãƒ—ã—ã¦ã„ã‚‹å ´åˆ

ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ãªãã€Œæ‰‹æ›¸ãã§åˆ†å‰²ã€ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒˆã€‚
ã“ã®å ´åˆã‚‚è€ƒãˆæ–¹ã¯åŒã˜ã§ã™ã€‚

```python
from sklearn.model_selection import train_test_split

oof_preds = np.zeros(len(train_x))

for seed in [0, 1, 2, 3, 4]:
    X_train, X_val, y_train, y_val, idx_train, idx_val = train_test_split(
        train_x, train_y, np.arange(len(train_x)), test_size=0.2, random_state=seed
    )
    model = lgb.LGBMRegressor()
    model.fit(X_train, y_train)
    val_pred = model.predict(X_val)
    
    oof_preds[idx_val] = val_pred
```

### ãƒã‚¤ãƒ³ãƒˆ

* `train_test_split` ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã•ãªã„ã®ã§ã€è‡ªåˆ†ã§ä½œã‚‹å¿…è¦ãŒã‚ã‚‹
  â†’ `np.arange(len(train_x))` ã‚’ä¸€ç·’ã«splitã—ã¦å¯¾å¿œ

---

## â‘£ TimeSeriesSplitï¼ˆæ™‚ç³»åˆ—CVï¼‰ã®å ´åˆ

Kaggleã§ã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã‚ˆãç™»å ´ã—ã¾ã™ã€‚

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
oof_preds = np.zeros(len(train_x))

for fold, (train_idx, val_idx) in enumerate(tscv.split(train_x)):
    model = lgb.LGBMRegressor()
    model.fit(train_x.iloc[train_idx], train_y.iloc[train_idx])
    val_pred = model.predict(train_x.iloc[val_idx])
    
    oof_preds[val_idx] = val_pred
```

### ãƒã‚¤ãƒ³ãƒˆ

* `shuffle=True` ãŒä½¿ãˆãªã„
* æœªæ¥æƒ…å ±ã‚’æ¼ã‚‰ã•ãªã„ã‚ˆã†ã«ã€Œtrain < valã€ã¨ã„ã†é †åºãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹

---

# âœ… ã¾ã¨ã‚

* **å¿…ãšã‚ã‚‹ã¹ãè¡Œ** â†’ `oof_preds[val_idx] = model.predict(X_val)`
* ã©ã®CVæ‰‹æ³•ã§ã‚‚ã€**æ¤œè¨¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«äºˆæ¸¬ã‚’åŸ‹ã‚è¾¼ã‚€**ã®ãŒå…±é€šåŸå‰‡
* æœ€å¾Œã« `np.save("oof.npy", oof_preds)` ã—ã¦åé›†ã§ãã‚‹å½¢ã«ã™ã‚‹

---

ã„ã„è³ªå•ã§ã™ ğŸ‘ã€€ã“ã“ã¯èª¤è§£ã—ã‚„ã™ã„ãƒã‚¤ãƒ³ãƒˆãªã®ã§ã€ä¸å¯§ã«æ•´ç†ã—ã¦ã¿ã¾ã™ã€‚

---

## 1. OOF ã®å®šç¾©

OOF (Out-Of-Fold) äºˆæ¸¬ã¨ã¯ï¼š

* ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ **å­¦ç¿’ã«ä½¿ã‚ãªã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆ= validation foldï¼‰ã«å¯¾ã™ã‚‹äºˆæ¸¬** ã®ã“ã¨ã€‚
* ã¤ã¾ã‚Šã€ŒæœªçŸ¥ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬ã«è¿‘ã„ã‚‚ã®ã€ã‚’å†ç¾ã—ã¦ã„ã¾ã™ã€‚

ä¾‹ãˆã° 5-fold CV ã®å ´åˆï¼š

* Fold1: train(fold2-5) â†’ predict(fold1)
* Fold2: train(fold1,3-5) â†’ predict(fold2)
* â€¦
* ã“ã‚Œã‚’å…¨éƒ¨é›†ã‚ã‚Œã°ã€trainå…¨ä½“ã«å¯¾ã™ã‚‹ã€ŒæœªçŸ¥ãƒ‡ãƒ¼ã‚¿é¢¨ã®äºˆæ¸¬ã€ãŒæƒã„ã¾ã™ã€‚
  â¡ï¸ ã“ã‚ŒãŒ OOF ã§ã™ã€‚

---

## 2. Full train ã§ã®äºˆæ¸¬ã¯ãªãœ OOF ã«ãªã‚‰ãªã„ã‹ï¼Ÿ

ã‚‚ã—å…¨trainãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«ã€å†ã³ãã® **åŒã˜trainãƒ‡ãƒ¼ã‚¿** ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€

* ãƒ¢ãƒ‡ãƒ«ã¯ã™ã§ã«ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œè¦‹ã¦ã€å­¦ç¿’ã—ã¦ã„ã‚‹
* ãã®ãŸã‚äºˆæ¸¬ã¯ã€ŒæœªçŸ¥ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ¨è«–ã€ã§ã¯ãªãã€ã€Œæš—è¨˜ã«è¿‘ã„ç­”ãˆã€ã«ãªã‚Šã‚„ã™ã„
* ã“ã‚Œã‚’ç‰¹å¾´é‡ã«ä½¿ã†ã¨ **æœ¬ç•ªï¼ˆtestï¼‰ã§ã¯å¾—ã‚‰ã‚Œãªã„ä¸å…¬å¹³ãªæƒ…å ±**ãŒtrainå´ã«æ··ã–ã‚‹

â¡ï¸ ã“ã‚Œã‚’ **ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯** ã¨å‘¼ã³ã¾ã™ã€‚

---

## 3. ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ç†è§£

ãŸã¨ãˆã°è©¦é¨“å‹‰å¼·ã‚’ã—ã¦ã„ã‚‹ã¨ãï¼š

* **OOF** = æ¨¡è©¦ã‚’ä½¿ã£ã¦ã€ã¾ã å‡ºé¡Œã•ã‚Œã¦ã„ãªã„æœ¬ç•ªè©¦é¨“ã®é›°å›²æ°—ã‚’ç¢ºã‹ã‚ã‚‹
* **Full train ã®è‡ªå·±äºˆæ¸¬** = å‹‰å¼·ã—ãŸå‚è€ƒæ›¸ã®å•é¡Œã‚’è§£ãç›´ã—ã¦ã€Œã»ã‚‰è§£ã‘ãŸï¼ã€ã¨è¨€ã£ã¦ã„ã‚‹çŠ¶æ…‹

å¾Œè€…ã¯æˆç¸¾ã®æŒ‡æ¨™ã«ã¯ãªã‚Šã¾ã›ã‚“ã—ã€stackingç‰¹å¾´é‡ã«ã™ã‚‹ã¨ **æœ¬ç•ªï¼ˆæœªçŸ¥ãƒ‡ãƒ¼ã‚¿ï¼‰ã§ã®å¼·ã•ã‚’åæ˜ ã—ãªã„**ã®ã§å±é™ºã§ã™ã€‚

---

## 4. Stackingã«ãŠã‘ã‚‹æ­£ã—ã„æµã‚Œ

* **trainã®ç‰¹å¾´é‡**ã«ã¯ã€ŒOOFäºˆæ¸¬ã€ã‚’ä½¿ã†ï¼ˆæœªçŸ¥ãƒ‡ãƒ¼ã‚¿é¢¨ã ã‹ã‚‰OKï¼‰
* **testã®ç‰¹å¾´é‡**ã«ã¯ã€Œfull trainã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ã€ã‚’ä½¿ã†

ğŸ‘‰ ã“ã†ã™ã‚Œã° train/test ã®çŠ¶æ³ãŒæƒã£ã¦ã€å…¬å¹³ãªstackingãŒã§ãã¾ã™ã€‚

---

## ã¾ã¨ã‚

* OOF = CVã®validationäºˆæ¸¬ï¼ˆæœªçŸ¥ãƒ‡ãƒ¼ã‚¿æ‰±ã„ã ã‹ã‚‰å®‰å…¨ï¼‰
* Full train ã® trainäºˆæ¸¬ = ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼ˆæ—¢çŸ¥ãƒ‡ãƒ¼ã‚¿ã ã‹ã‚‰ãƒ€ãƒ¡ï¼‰
* ã§ã‚‚ Full train ã® testäºˆæ¸¬ = æå‡ºç”¨ãƒ»stackingç”¨ã«OK

---



